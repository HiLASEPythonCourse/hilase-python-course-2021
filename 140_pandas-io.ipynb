{"cells":[{"cell_type":"markdown","source":"# Pandas - Reading data\n\nThis notebook is the second part of the series devoted to the pandas library.\n\nIt explores the ways how data can be imported into DataFrames. \n\nMore details can be found in the official documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/io.html\n\nMost of the functions for reading data are named `pandas.read_XXX`, where XXX is the format used. We will go through several commonly used ones.","metadata":{"cell_id":"00000-e201ad38-bab3-4752-bb9d-0ea4e579a6e5","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### This tutorial data sets origins\n\n* IMDB: https://datasets.imdbws.com/\n* Box office (Kaggle / TMDB): https://www.kaggle.com/c/tmdb-box-office-prediction/data\n* Awards: https://en.wikipedia.org/wiki/List_of_Academy_Award-winning_films\n* Rotten Tomatoes: https://data.world/prasert/rotten-tomatoes-top-movies-by-genre\n* Guardian: https://www.theguardian.com/news/datablog/2010/oct/16/greatest-films-of-all-time\n* Wikipedia movies: https://github.com/prust/wikipedia-movie-data\n","metadata":{"cell_id":"00001-d64efb64-57c0-4e7d-90e7-5c28e5caf811","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00003-db6af2c3-907f-4567-a1a7-e350cebe403b","deepnote_to_be_reexecuted":false,"source_hash":"6e1324e7","execution_start":1611499547261,"execution_millis":0,"deepnote_cell_type":"code"},"source":"# List functions for input in pandas.\n\nprint(\"\\n\".join(method for method in dir(pd) if method.startswith(\"read_\")))","execution_count":13,"outputs":[{"name":"stdout","text":"read_clipboard\nread_csv\nread_excel\nread_feather\nread_fwf\nread_gbq\nread_hdf\nread_html\nread_json\nread_orc\nread_parquet\nread_pickle\nread_sas\nread_spss\nread_sql\nread_sql_query\nread_sql_table\nread_stata\nread_table\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Read CSV\n\nNowadays, a lot of data comes in the textual Comma-separated values format (CSV).\nAlthough not properly standardized, it is the de-facto standard for files that are not\nhuge and are meant to be read by human eyes too.\n\nLet's read the population of U.S. states (and several other territories that we will need later):","metadata":{"cell_id":"00004-19bf39d6-b1e0-49c1-9a53-aeb25d94db0b","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00006-288c35a0-b7bc-4521-b7e7-06243e04539f","deepnote_to_be_reexecuted":false,"source_hash":"6caee636","execution_start":1611517775367,"execution_millis":15,"deepnote_cell_type":"code"},"source":"territories = pd.read_csv(\"data/us_state_population.csv\")\nterritories.head(9)","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":9,"column_count":2,"columns":[{"name":"Territory","dtype":"object","stats":{"unique_count":9,"nan_count":0,"categories":[{"name":"California","count":1},{"name":"Texas","count":1},{"name":"7 others","count":7}]}},{"name":"Population","dtype":"int64","stats":{"unique_count":9,"nan_count":0,"min":10600823,"max":39368078,"histogram":[{"bin_start":10600823,"bin_end":13477548.5,"count":5},{"bin_start":13477548.5,"bin_end":16354274,"count":0},{"bin_start":16354274,"bin_end":19230999.5,"count":0},{"bin_start":19230999.5,"bin_end":22107725,"count":2},{"bin_start":22107725,"bin_end":24984450.5,"count":0},{"bin_start":24984450.5,"bin_end":27861176,"count":0},{"bin_start":27861176,"bin_end":30737901.5,"count":1},{"bin_start":30737901.5,"bin_end":33614627,"count":0},{"bin_start":33614627,"bin_end":36491352.5,"count":0},{"bin_start":36491352.5,"bin_end":39368078,"count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows_top":[{"Territory":"California","Population":39368078,"_deepnote_index_column":0},{"Territory":"Texas","Population":29360759,"_deepnote_index_column":1},{"Territory":"Florida","Population":21733312,"_deepnote_index_column":2},{"Territory":"New York","Population":19336776,"_deepnote_index_column":3},{"Territory":"Pennsylvania","Population":12783254,"_deepnote_index_column":4},{"Territory":"Illinois","Population":12587530,"_deepnote_index_column":5},{"Territory":"Ohio","Population":11693217,"_deepnote_index_column":6},{"Territory":"Georgia","Population":10710017,"_deepnote_index_column":7},{"Territory":"North Carolina","Population":10600823,"_deepnote_index_column":8}],"rows_bottom":null},"text/plain":"        Territory  Population\n0      California    39368078\n1           Texas    29360759\n2         Florida    21733312\n3        New York    19336776\n4    Pennsylvania    12783254\n5        Illinois    12587530\n6            Ohio    11693217\n7         Georgia    10710017\n8  North Carolina    10600823","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Territory</th>\n      <th>Population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>California</td>\n      <td>39368078</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Texas</td>\n      <td>29360759</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Florida</td>\n      <td>21733312</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New York</td>\n      <td>19336776</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pennsylvania</td>\n      <td>12783254</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Illinois</td>\n      <td>12587530</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Ohio</td>\n      <td>11693217</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Georgia</td>\n      <td>10710017</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>North Carolina</td>\n      <td>10600823</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The automatic data type parsing automatically converts columns to appropriate types:","metadata":{"cell_id":"00007-bd4c50fa-afe7-4374-8b26-04c57b50c1c2","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00008-ef540848-1b48-422a-ad8e-0e8c690c126c","deepnote_to_be_reexecuted":false,"source_hash":"ec8087cf","execution_millis":1,"execution_start":1611517800058,"deepnote_cell_type":"code"},"source":"territories.dtypes","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"Territory     object\nPopulation     int64\ndtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"Sometimes the CSV input does not work out of the box. Although pandas automatically understands and reads zipped files,\nit usually does not automatically infer the file format - for details, see the `read_csv` documentation here: \nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html","metadata":{"cell_id":"00009-42bb0698-7876-4cd3-be26-6a6bff8f9ef5","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00010-e6b71d78-507e-4e6d-b75d-e953899809c1","deepnote_cell_type":"code"},"source":"pd.read_csv('../data/title.basics.tsv.gz')","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"...in this case, the CSV file does not use commas to separate values. Therefore, we need to specify a few more arguments:","metadata":{"cell_id":"00011-7c02b57e-8c69-4c63-a3dd-1b2cef65fc1f","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00012-d8dc660f-aa44-4b11-8949-902e30dbe3fd","deepnote_cell_type":"code"},"source":"imdb_titles = pd.read_csv('../data/title.basics.tsv.gz', sep='\\t')\nimdb_titles.head()","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Noticed the `\\N` endYear values?\n\n**Exercise:** Use `na_values` argument to mark `\\N` as a null (missing) value. ","metadata":{"cell_id":"00013-ced9c679-ea5b-4faa-a0b4-7804b363071b","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00014-3609e8e2-f3fe-4163-909e-1ff304c60cbf","deepnote_cell_type":"code"},"source":"%exercise\n\nimdb_titles = pd.read_csv('../data/title.basics.tsv.gz', sep='\\t', na_values=...)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00015-d42f5adb-6736-40b2-94e6-3253cb6f5ab9","deepnote_cell_type":"code"},"source":"%validate\n\nassert pd.isna(imdb_titles.loc[0, 'endYear'])","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"See the difference?","metadata":{"cell_id":"00016-34286dd8-9155-4e7b-9ef7-f00d95a4f0e4","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00017-8a5f1b06-98ee-40f4-8152-ba062abf7f2d","deepnote_cell_type":"code"},"source":"imdb_titles.head()","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read Excel\n\nLet's read the list of laser accidents involving ","metadata":{"cell_id":"00018-659b7d33-9d66-4ec8-b683-9df4f9064f56","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00019-6c397e4d-b954-4b9c-99a8-37d5fcab47bf","deepnote_cell_type":"code"},"source":"pd.read_excel(\"../data/guardian-greatest_films_of_all_time.xlsx\")","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hmmmmph... Pandas parsed just the first spreadsheet. Let's see what are the options. If in doubt, look in the documentation:\nhttps://pandas.pydata.org/pandas-docs/stable/reference/io.html#excel","metadata":{"cell_id":"00020-b42285e8-9134-47e7-92f1-7afb20db9b6e","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00021-f36a996d-728b-48d1-8243-e8686283d6b2","deepnote_cell_type":"code"},"source":"xlsx = pd.io.excel.ExcelFile(\"../data/guardian-greatest_films_of_all_time.xlsx\")\nxlsx","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00022-fccbf5a1-72d5-47e0-bb1b-65d3ec1f5486","deepnote_cell_type":"code"},"source":"xlsx.sheet_names","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00023-e2bd3600-d66c-4a07-9e73-49ff2b1f4646","deepnote_cell_type":"code"},"source":"xlsx.parse(\"HORROR\")","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00024-7f138dfc-84e2-4142-a619-fb0318d37212","deepnote_cell_type":"code"},"source":"%exercise\n\ncrimes =...                    # Find the table of crime movies\ntenth_best = crimes.loc[...]   # Find the 10-th best crime movie\nmovie_name = ...               # Get the name of the movie\n\n# display\nmovie_name","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00025-a5e27f2d-5f02-43c9-a3be-fb7caa2bf6b1","deepnote_cell_type":"code"},"source":"%validate\n\nassert movie_name[7:9] == \"la\"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read HTML (Optional)\n\nPandas is able to scrape data from tables embedded in web pages using the `read_html` function.\nThis might or might not bring you good results and probably you will have to tweak your\ndata frame manually. But it is a good starting point - much better than being forced to parse\nthe HTML ourselves!\n\nLet's download a list of highest-grossing films from wikipedia!","metadata":{"cell_id":"00031-0c51493e-79b9-4dc5-9831-da39da3f613c","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00032-cbfdb276-ab04-4546-b3e1-947ab782dd81","deepnote_cell_type":"code"},"source":"tables = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\")\ntype(tables), len(tables)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Does the page really contain 95 tables? The number is quite high and we must check which of the tables\nare meaningful and which are not. We are mostly interested in the first displayed one.\n\n**Exercise:** Find **i** to obtain the right table:","metadata":{"cell_id":"00033-fd7a867e-a5ad-4323-bd1a-5aa2181c34e8","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00034-c09dc691-6b17-42aa-9c93-42a4332641aa","deepnote_cell_type":"code"},"source":"%exercise\n\ni = ...\n\ntable = tables[i]\ntable.head(10)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Write CSV\n\nPandas is able to write to many various formats but the usage is similar. ","metadata":{"cell_id":"00036-8a763cb8-5162-4a37-a63f-ba2017d059f7","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00037-9b564bf0-d7d9-4284-9bc7-2810a864192e","deepnote_cell_type":"code"},"source":"award_table.to_csv(\"awards.csv\", index=False)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00038-21694f3e-44f0-443c-bf1f-1c90b0bce77a","deepnote_cell_type":"code"},"source":"%head awards.csv 10","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: When done with this notebook, we suggest that you shutdown the kernel to free the memory.","metadata":{"cell_id":"00042-2d7a2325-7f33-408b-8f2e-a11fa2ad440e","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00043-0c2a62b3-6cad-40e2-af71-5f8f7568629c","deepnote_cell_type":"code"},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"deepnote_notebook_id":"d73db639-d466-448c-8264-747a899bc058","deepnote_execution_queue":[]}}