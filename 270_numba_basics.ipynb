{"cells":[{"cell_type":"markdown","source":"This notebook has been **adopted** from https://github.com/numba/numba-examples/tree/master/tutorials/nasa_apps_oct_2019: **Many thanks** to the original authors!","metadata":{"cell_id":"00000-16c91e8d-8a12-4c09-a366-d48b0acbc667","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"# An Introduction to Numba\n\n","metadata":{"cell_id":"00001-6d351a67-506f-4290-8ad7-d92925ae1c89","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Why does Numba exist?\nThe idea surrounding Numba is to create the ability to extend Python with Python itself. It gets your code performance/capabilities that you just cannot otherwise achieve without C extensions/Cython/Pythran/&lt;insert extension creation package that calls a compiler here&gt;!\n\n## Conventions used throughout this tutorial series:\n\n * Tasks (exercises for the reader) are marked up in bold blue, like this:<h3><span style=\"color:blue\"> Task 1 </span></h3><br>\n\n * Hints/tips/suggestions/things to think about are in bold green, like this:\n<h4><span style=\"color:green\"> HINT: this is a hint </span></h4>\n\n\n## What is Numba?!\n\n**Numba is a type specialising just-in-time (JIT) compiler for Python functions.**\n\nIt is most often used via a decorator...\n\nSimplest example with the simplest decorator:","metadata":{"cell_id":"00002-d434a1ef-f252-4860-b538-301de99aae67","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00003-0193dce0-0958-4c9b-a1c8-c89ac37e0827","deepnote_to_be_reexecuted":false,"source_hash":"56f20993","execution_millis":573,"execution_start":1614540234570,"deepnote_cell_type":"code"},"source":"from numba import njit\n\n@njit\ndef add_one(x):\n    return x + 1","execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"In the above the ``njit`` decorator was imported and applied to a simple function (\"Numba is ... for Python functions\"). No compilation has occurred yet! Let's call the function with an integer:\n\n<h3><span style=\"color:blue\"> Task 1: call the `add_one` function with an integer input</span></h3>","metadata":{"cell_id":"00004-5a4319f4-49a8-41fc-a8c9-25fd49cdf2e5","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00005-3159eb15-6b39-4f38-a27c-9504b154e813","deepnote_cell_type":"code"},"source":"# You do this! Call `add_one` with an integer here...","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ðŸŽ‰ Congratulations ðŸŽ‰, you just used one of the world's most powerful compliation chains (LLVM!)!\n\nInvoking the function makes compilation take place, this is what the just-in-time part is about (\"Numba is a ... just-in-time compiler\"). No compilation occurs until it is needed, and once it has occurred it is cached in process to be reused. Calling the function again with another integer will use the cached code path, it does not need to recompile.","metadata":{"cell_id":"00006-72e53c62-ed10-4f69-93b7-a8d9db0b77ec","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00007-145d2044-eb41-4dfa-aaad-4eaec9760168","deepnote_to_be_reexecuted":false,"source_hash":"e35a31ec","execution_millis":111,"execution_start":1614540252171,"deepnote_cell_type":"code"},"source":"add_one(-129)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"-128"},"metadata":{}}]},{"cell_type":"markdown","source":"Now let's call function with a float.","metadata":{"cell_id":"00008-0363b5d2-2f69-4c16-9a0d-089b43c5a32f","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00009-b9cdca20-fb76-4c32-8fa1-ac57a5622132","deepnote_to_be_reexecuted":false,"source_hash":"bf99112d","execution_millis":13,"execution_start":1614540253392,"deepnote_cell_type":"code"},"source":"add_one(12.34)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"13.34"},"metadata":{}}]},{"cell_type":"markdown","source":"This of course works, but a new specialisation was needed, Numba recompiled the function for floats.\n\n<h4><span style=\"color:green\">Remember: Numba is a compiler, specialisation leads to optimisation</span></h4>\n\n\nEach time a new **TYPE** of input is encountered a new specialisation for the function is being compiled. We can look at these via the `.signatures` attribute:","metadata":{"cell_id":"00010-cf4643e7-5e6b-4516-977e-de1606cb8fa6","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00011-d100e72a-6b33-4f01-8658-28ce2555fbe4","deepnote_to_be_reexecuted":false,"source_hash":"b7fb4f63","execution_start":1614540255029,"execution_millis":22,"deepnote_cell_type":"code"},"source":"add_one.signatures","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"[(int64,), (float64,)]"},"metadata":{}}]},{"cell_type":"markdown","source":"this is what the type specilisation part means (Numba is a type specialising ... compiler).\n\nAs the `.signatures` attribute is simply a list of signatures (each new signature is just appended to the list) it's easy to retrieve a particular function signature. For example, this selects the signature for the first specialisation (the one with the integer argument), it's at index zero as this type was encountered first:","metadata":{"cell_id":"00012-1797ecfc-e401-4b55-a048-20808c83f3f7","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00013-fc929d6a-b0b2-497e-9237-104d5b9ac9bf","deepnote_to_be_reexecuted":false,"source_hash":"982eb0cf","execution_start":1614540257091,"execution_millis":8,"deepnote_cell_type":"code"},"source":"add_one.signatures[0]","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"(int64,)"},"metadata":{}}]},{"cell_type":"markdown","source":"It in fact has to work out the type of every variable based on the input types and the operations in the function, this is called \"typing\" a function and happens through a process called \"type inference\".","metadata":{"cell_id":"00014-e6035818-68d8-44a2-be55-cf120da5d8ab","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## How does Numba work?\n\n![How Numba Works](How_Numba_Works.png)\n\n#### <span style=\"color:green\"> TIP: Understanding type inference is really important, most errors you are going to see are because Numba couldn't figure out what type something should be. <br><br>Numba takes a function in a dynamic language and makes a type-static compiled verion of it!</span> \n\n## What did Numba do?!\n\nWe've seen that Numba does multiple stages of transforms to go from bytecode to machine code. Three places that are important to look at are:\n1. The Numba intermediate representation (IR) level, this shows type information.\n   Access it via `.inspect_types` on a Numba JIT decorated function.\n2. The LLVM IR level, this shows the LLVM IR that Numba generated to pass to LLVM.\n   Access it via `.inspect_llvm` on a Numba JIT decorated function.\n3. The assembly level, this shows the disassembly of the compiled object.\n   Access it via `.inspect_asm` on a Numba JIT decorated function.\n\nEach of these methods takes a signature `kwarg` (like one obtained from `.signatures` above) as these representations are also type-specialised.\n\n<h3><span style=\"color:blue\"> Task 2: Using the `add_one` function from above, for the `float64` signature take a look at the various levels of transforms.</span></h3>","metadata":{"cell_id":"00015-79836866-3cd8-49b2-bde3-69307f17c7bc","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00016-64d26f8d-aa23-4a07-b71f-60629ab39fff","deepnote_cell_type":"code"},"source":"# first select the `float64` signature\nmy_sig = # You write this!\nprint(my_sig)\n\n# Level 1, print the types using `.inspect_types()`, make sure to specify the `signature` kwarg\nprint(add_one.inspect_types())","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00017-2708aa8b-f135-4bae-9eea-2843eaa87f80","deepnote_cell_type":"code"},"source":"# Level 2, print the LLVM IR using `.inspect_llvm()`\nprint(# You write this!)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"cell_id":"00018-4c053313-d99b-4a20-a6a7-2be653db4722","deepnote_cell_type":"code"},"source":"# Level 3, print the disassembly using `.inspect_asm()`\nprint(# You write this!)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Benchmarking\n\nAs we saw above, Numba JIT compiles specialisation of a function based on the input types. This means the first invocation is going to involve compilation, and subsequent are going to be from cache. Let's define a more involved function and look at how to benchmark Numba:","metadata":{"cell_id":"00019-4c991873-86b6-45f1-b973-520d2b36399c","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00020-82caf453-29ca-4125-a93a-11f6146d8263","deepnote_cell_type":"code"},"source":"import math\n\n@njit\ndef hypot(x, y):\n    # Implementation from https://en.wikipedia.org/wiki/Hypot\n    x = abs(x);\n    y = abs(y);\n    t = min(x, y);\n    x = max(x, y);\n    t = t / x;\n    return x * math.sqrt(1+t*t)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `%timeit` magic is appropriate for timing Numba, it runs repeated loops so the cost of compiling the function is amortized.","metadata":{"cell_id":"00021-75f34430-c009-4c9c-8d48-5a5880ec2fb6","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00022-3278ab3c-0c31-4ddb-aebd-ba480ca23b05","deepnote_cell_type":"code"},"source":"%timeit hypot(3.0, 4.0)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All Numba `@njit` decorated functions have a `.py_func` attribute which holds reference to the pure Python function, we can use this to check the Python interpreter performance for the above function.","metadata":{"cell_id":"00023-7daf8c80-d2e7-42e8-b3b4-03f7b9372e0e","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00024-460bd675-4f7f-4b53-9d87-5562866e6484","deepnote_cell_type":"code"},"source":"%timeit hypot.py_func(3.0, 4.0)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style=\"color:green\"> **TIP: The most common mistake make when reporting performance results is reporting the execution time as the compilation time along with the execution time.** </span>","metadata":{"cell_id":"00025-c7831bda-a291-4777-9375-35af9158f3ca","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Loops?!\n\nNumPy is amazing, but a side effect of the \"vectorisation\" paradigm is having to avoid loops. Numba is a compiler, compilers like loops.","metadata":{"cell_id":"00026-87415044-5133-4c14-8187-e505f167be1b","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00027-251d7a4d-a184-44cc-a135-63ca4c2eed10","deepnote_cell_type":"code"},"source":"import numpy as np\nN = 1000\nnp.random.seed(0)\nX = np.random.rand((N * N)).reshape((N,  N))\n\n@njit\ndef awkward_sine(a):\n    return np.imag(np.exp(1j * a))\n\n# check result\nnp.testing.assert_allclose(awkward_sine(X), np.sin(X))","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the performance of the NumPy implementation running in the interpreter:","metadata":{"cell_id":"00028-dd12d5ab-da36-4bf6-a422-03d0628281c4","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"scrolled":true,"cell_id":"00029-b3e3030e-14ea-41c7-8b8f-a6e7b32e8479","deepnote_cell_type":"code"},"source":"%timeit awkward_sine.py_func(X)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the performance of Numba JIT version:","metadata":{"cell_id":"00030-4bbe767b-716c-4034-a2a1-a2b8d501c584","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00031-3b378089-91e8-4886-9287-f35525eb904b","deepnote_cell_type":"code"},"source":"%timeit awkward_sine(X)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:blue\"> Task 3a: Reimplement the above `awkward_sine` function with explicit looping using the template below...</span></h3>","metadata":{"cell_id":"00032-c40d3a48-01d7-45e4-9d24-3e4af1d717d0","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00033-502e9af5-ea2e-429d-afa0-651ce4049feb","deepnote_cell_type":"code"},"source":"@njit\ndef awkward_sine_loops(a):\n    m, n = a.shape\n    result = np.empty_like(a)\n    # You write this part!\n    return result\n\n# check result\nnp.testing.assert_allclose(awkward_sine_loops(X), np.sin(X))","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:blue\"> Task 3b: Check the performance of the loop based function above: </span>","metadata":{"cell_id":"00034-08c9a79a-06e4-4dd0-bbdf-5727615f8281","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00035-a6ace2b1-0e19-4b91-9886-7cf455dc4015","deepnote_cell_type":"code"},"source":"%timeit awkward_sine_loops(X)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Assessing Performance\n\nAbove we saw Numba JIT out perform NumPy in both a vectorised and a loop induced version. The loop version was quickest by some margin.\n\n#### <span style=\"color:green\"> Discussion: What might happen in this similar case? </span>","metadata":{"cell_id":"00036-ce4577f0-114c-49cf-92d5-b089a7466aee","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00037-10ae0b52-3a09-43a3-8828-df84411f8b44","deepnote_cell_type":"code"},"source":"@njit\ndef awkward_exp(a):\n    return np.cosh(a) + np.sinh(a)\n\n# check result\nnp.testing.assert_allclose(awkward_exp(X), np.exp(X))","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the performance of the NumPy implementation running in the interpreter:","metadata":{"cell_id":"00038-8194f6b9-e5cd-4da9-a9ef-53a20f5d0563","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00039-207c2b50-eb01-4475-b121-f3f3613c889a","deepnote_cell_type":"code"},"source":"%timeit awkward_exp.py_func(X)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the performance of Numba JIT version:","metadata":{"cell_id":"00040-1c7e134d-6ae3-492b-87dc-213539fb1501","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00041-eecb8d16-98d9-4932-b163-f5e64b71a5b4","deepnote_cell_type":"code"},"source":"%timeit awkward_exp(X)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above we saw that loops made a difference, try that trick again...","metadata":{"cell_id":"00042-74e0395b-d00f-4ebd-96fe-741ea7ae1120","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00043-dcdc3252-143b-4b2f-afa9-a4ad70244a3f","deepnote_cell_type":"code"},"source":"@njit\ndef awkward_exp_loops(a):\n    m, n = a.shape\n    result = np.empty_like(a)\n    for i in range(m):\n        for j in range(n):\n            result[i, j] = np.cosh(a[i, j]) + np.sinh(a[i, j])\n    return result\n            \n# time it\n%timeit awkward_exp_loops(X)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's switch on `fastmath`, this plumbs in Intel's Short Vector Math library (SVML) which swaps out `libm` functions for vectorized ones.","metadata":{"cell_id":"00044-92d6916c-a803-41fc-9c3c-d3b5832371e4","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"scrolled":false,"cell_id":"00045-71ad2955-2fbb-4f54-b2c2-80a44e978587","deepnote_cell_type":"code"},"source":"@njit(fastmath=True)\ndef awkward_exp_loops_fastmath(a):\n    m, n = a.shape\n    result = np.empty_like(a)\n    for i in range(m):\n        for j in range(n):\n            result[i, j] = np.cosh(a[i, j]) + np.sinh(a[i, j])\n    return result\n\n           \n%timeit awkward_exp_loops_fastmath(X)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That made things a bit quicker but NumPy beat Numba all both cases...\n\n#### <span style=\"color:green\"> Answer: Anaconda NumPy ``ufunc`` behaviour is hugely optimised and uses MKL VML internally. </span>\n","metadata":{"cell_id":"00046-b81b2707-21a9-4673-b631-8312c41780bf","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Performance Tips:\n\nDo:\n * Write good tests for the correctness of your code before using the JIT\n * Write a good performance harness for your code:\n   * Use real data/representative input\n   * Keep track of measurements\n\nDo not:\n\n* Include compilation time in the execution time.\n* Drag race tiny functions as an assessment of Numba's ability, Numba has dispatch cost:","metadata":{"cell_id":"00047-20bfce06-bb62-4aa6-a0f1-2a08601f0b5b","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00048-f6186c3b-cd9d-40f4-9253-422db5cd5641","deepnote_cell_type":"code"},"source":"%timeit add_one(1)\n%timeit add_one.py_func(1)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Drag race fundamental math operations:","metadata":{"cell_id":"00049-a868f2d0-d9ae-4b50-9301-b6061e9075aa","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00050-db90426d-5e2d-4b93-9516-e249d2a947ee","deepnote_cell_type":"code"},"source":"@njit\ndef jit_cos(x):\n    return math.cos(x)\n\n%timeit jit_cos(12.34)\n%timeit jit_cos.py_func(12.34)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Expect Numba to outperform BLAS:","metadata":{"cell_id":"00051-58413242-d557-49c2-9700-06f0cde57d28","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00052-0d77c73a-1ff9-4cbc-bd15-9a577f6d39f2","deepnote_cell_type":"code"},"source":"@njit\ndef dgemv(A, x):\n    m, n = A.shape\n    acc = np.zeros((m,))\n    for i in range(m):\n        for j in range(n):\n            acc[i] += A[i, j] * x[j]\n    \n@njit\ndef call_dot(A, x):\n    return np.dot(A, x) # Numba will defer this to BLAS::XGEMV\n\n%timeit dgemv(X, X[0])\n%timeit call_dot(X, X[0])\n%timeit call_dot.py_func(X, X[0])","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You wouldn't expect Fortran/C to do any better in the above situations, Numba is the same, internally it tries to make sensible decisions.","metadata":{"cell_id":"00053-760effbf-523e-419e-89f8-b2375c2cecd9","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## The importance of measurement:\n\nFind the root of `f(x) = cos(x) + 1`. Use the Newton-Raphson algorithm. Use SciPy `optimize.newton` as a performance baseline.","metadata":{"cell_id":"00054-9532ecab-7bd8-4ae4-b8d6-3a824e9c2c59","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00055-84c4ad3f-0855-4a30-8773-a0855417ab32","deepnote_cell_type":"code"},"source":"from scipy import optimize\n\ndef f(x):\n    return np.cos(x) + 1\n\ndef dfdx(x):\n    return -np.sin(x)\n\ntol = 1e-7 # convergence tolerance\nmax_it = 50 # maximum iterations\nx0 = 0.5 # starting guess\n\n%timeit optimize.newton(f, x0, fprime=dfdx, tol=tol, maxiter=max_it)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><span style=\"color:blue\"> Task 4:  Write your own Newton-Raphson implementation based on based on pseudo-code from <a href=\"https://en.wikipedia.org/wiki/Newton%27s_method#Pseudocode\">Wikipedia</a>.</span></h3>","metadata":{"cell_id":"00056-b8662d77-0e41-48b7-9f04-2c83b6c66ddc","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00057-038896fc-de47-4570-8849-0103bb110c11","deepnote_cell_type":"code"},"source":"@njit\ndef NR_root(f, dfdx, x0, max_it=max_it, eps=tol):\n    converged = False\n    # You write this part!\n    if converged:\n        return x1\n    else:\n        raise RuntimeError(\"Solution did not converge\")\n\n# if the above is \"correct\", this will pass\nnp.testing.assert_allclose(NR_root.py_func(f, dfdx, x0), np.pi)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time the Python function:","metadata":{"cell_id":"00058-51e94ebf-af30-43fb-bc33-4f78e6341e4b","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00059-daddd788-3e4e-438b-bd23-fea67956454e","deepnote_cell_type":"code"},"source":"%timeit NR_root.py_func(f, dfdx, x0)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time the Python function with JIT compiled objective functions:","metadata":{"cell_id":"00060-d2e25adc-c060-427f-afe5-d918d9d9fb7a","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00061-cad185ad-2cf0-47db-b7e5-69829d61f926","deepnote_cell_type":"code"},"source":"f_jit = njit(f)\ndfdx_jit = njit(dfdx)\n\n%timeit NR_root.py_func(f_jit, dfdx_jit, x0)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time the JIT compiled function with JIT compiled objective functions:","metadata":{"cell_id":"00062-05c7ba3f-ed51-4a3b-8e01-e086b8d35717","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00063-8b80b4e1-c59a-468f-8a9f-10c06eab82e4","deepnote_cell_type":"code"},"source":"%timeit NR_root(f_jit, dfdx_jit, x0)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time SciPy with JIT compiled objective functions:","metadata":{"cell_id":"00064-235d9f51-924a-41cb-8990-e33dac118a01","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00065-a983eb19-2a8c-448a-880f-5026cb040f14","deepnote_cell_type":"code"},"source":"%timeit optimize.newton(f_jit, x0, fprime=dfdx_jit, tol=tol, maxiter=max_it)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's really lean on the fact we have a specialising compiler... performance comes from specialisation.","metadata":{"cell_id":"00066-a767ea5f-1d38-4f18-826c-e28541d82252","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00067-70cc9859-552f-4ad6-8004-1337fc81e122","deepnote_cell_type":"code"},"source":"def specialize(f, dfdx):\n    # Close over the objective functions so they are \"constant\"\n    # Numba will spot this and LLVM will inline them into the machine code\n    @njit\n    def NR_root(x0, max_it=max_it, eps=tol):\n        # Copy your NR function body from above here\n    return NR_root\n\nf_NR_root = specialize(f_jit, dfdx_jit)\n\n%timeit f_NR_root(x0, max_it, tol)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <span style=\"color:green\"> Discuss: What happened in the above?!</span>\n#### <span style=\"color:green\"> TIP: Experiment and time things!</span>","metadata":{"cell_id":"00068-18b384a3-b78b-4809-bf6f-74015bcbe0f2","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00069-cd89e345-a128-48dc-8ec6-114076f7ced0","deepnote_cell_type":"code"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=77a5caea-ff40-471d-8b4b-98dc66dd30c3' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"deepnote_notebook_id":"3c4b4926-48ae-4689-b511-218b21cf03bd","deepnote":{},"deepnote_execution_queue":[]}}